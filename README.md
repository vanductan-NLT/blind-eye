<div align="center">
<img width="1200" height="475" alt="Blind Eye Banner" src="https://github.com/user-attachments/assets/0aa67016-6eaf-458a-adb2-6e31a0763ed6" />

# ğŸ‘ï¸ Blind Eye

### AI-Powered Visual Companion for the Visually Impaired

[![Google Gemini](https://img.shields.io/badge/Powered%20by-Google%20Gemini-4285F4?style=for-the-badge&logo=google&logoColor=white)](https://ai.google.dev/)
[![React](https://img.shields.io/badge/React-18-61DAFB?style=for-the-badge&logo=react&logoColor=white)](https://reactjs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5-3178C6?style=for-the-badge&logo=typescript&logoColor=white)](https://www.typescriptlang.org/)
[![Vite](https://img.shields.io/badge/Vite-5-646CFF?style=for-the-badge&logo=vite&logoColor=white)](https://vitejs.dev/)

</div>

---

## ğŸŒŸ Overview

**Blind Eye** is a real-time AI-powered visual companion designed to assist visually impaired individuals in navigating their environment safely and independently. Using cutting-edge Google Gemini AI models, the app acts as a trusted friend walking beside the user, providing natural, conversational guidance about their surroundings.

### ğŸ¯ Key Features

| Feature | Description |
|---------|-------------|
| **ğŸš¶ Live Navigation Mode** | Continuous real-time guidance using camera feed. Warns about obstacles, stairs, and hazards using clock-face directions (e.g., "Chair at 2 o'clock, 3 steps away"). |
| **ğŸ¤ Voice Assistant (Ask AI)** | Voice-activated Q&A. Ask anything: "What's in front of me?", "Read this sign", "Is the path clear?" |
| **ğŸ§  Intelligent Model Routing** | Automatically selects the optimal AI model - Flash for quick responses, Gemini 3 Pro for complex analysis like reading documents. |
| **ğŸ“ Location-Aware** | Integrates with device GPS for context-aware navigation assistance. |
| **ğŸ”Š Text-to-Speech** | Clear, natural voice feedback for all guidance. |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        BLIND EYE APP                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Camera     â”‚  â”‚  Microphone  â”‚  â”‚    GPS Location      â”‚  â”‚
â”‚  â”‚   (WebRTC)   â”‚  â”‚  (Web API)   â”‚  â”‚    (Geolocation)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                 â”‚                      â”‚              â”‚
â”‚         â–¼                 â–¼                      â–¼              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    React Frontend                         â”‚  â”‚
â”‚  â”‚  â€¢ App.tsx (Main Controller)                              â”‚  â”‚
â”‚  â”‚  â€¢ HUD Component (User Interface)                         â”‚  â”‚
â”‚  â”‚  â€¢ useSpeechRecognition Hook                              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â”‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    Services Layer                          â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚ geminiService   â”‚ â”‚   liveClient    â”‚ â”‚speechService â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Model Router  â”‚ â”‚ â€¢ Real-time API â”‚ â”‚ â€¢ TTS Output â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Smart Assist  â”‚ â”‚ â€¢ Audio I/O     â”‚ â”‚              â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ Navigation    â”‚ â”‚ â€¢ Video Stream  â”‚ â”‚              â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚              â”‚                   â”‚                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                   â”‚
               â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GOOGLE GEMINI AI                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ gemini-2.5-flash â”‚  â”‚ gemini-3-pro    â”‚  â”‚ Gemini Live API â”‚  â”‚
â”‚  â”‚ (Fast responses) â”‚  â”‚ (Deep analysis) â”‚  â”‚ (Real-time)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Getting Started

### Prerequisites

- **Node.js** v18 or higher
- **Google Gemini API Key** ([Get one here](https://makersuite.google.com/app/apikey))
- Modern browser with camera and microphone access

### Installation

```bash
# Clone the repository
git clone https://github.com/vanductan-NLT/blind-eye.git
cd blind-eye

# Install dependencies
npm install

# Configure API key
cp .env.local.example .env.local
# Edit .env.local and add your GEMINI_API_KEY

# Start development server
npm run dev
```

### Environment Variables

Create a `.env.local` file in the project root:

```env
GEMINI_API_KEY=your_api_key_here
```

---

## ğŸ“± Usage

### Live Navigation Mode
1. Click **"START LIVE"** button
2. Point your camera forward as you walk
3. Receive continuous guidance like:
   - *"Path is clear, keep going straight."*
   - *"Stop! Stairs going down right in front of you."*
   - *"Chair at 2 o'clock, 3 steps away. Bear left."*

### Voice Assistant Mode
1. Click **"ASK AI"** button
2. Speak your question naturally
3. Examples:
   - "What's in front of me?"
   - "Read this sign"
   - "Is the path clear?"
   - "What color is this?"

---

## ğŸ§  AI Model Strategy

| Task Type | Model Used | Reason |
|-----------|------------|--------|
| Quick identification | `gemini-2.5-flash` | Speed priority |
| Document reading | `gemini-3-pro-preview` | Accuracy priority |
| Live navigation | `gemini-2.5-flash` | Real-time performance |
| Complex reasoning | `gemini-3-pro-preview` | Deep analysis |

The app uses an intelligent router that analyzes each query and automatically selects the optimal model.

---

## ğŸ› ï¸ Tech Stack

- **Frontend**: React 18, TypeScript, Vite
- **AI**: Google Gemini API, Gemini Live API
- **Speech**: Web Speech API (Recognition + Synthesis)
- **Camera**: WebRTC, react-webcam
- **Styling**: Tailwind CSS

---

## ğŸ“ Project Structure

```
blind-eye/
â”œâ”€â”€ App.tsx                 # Main application component
â”œâ”€â”€ components/
â”‚   â””â”€â”€ HUD.tsx             # User interface overlay
â”œâ”€â”€ hooks/
â”‚   â””â”€â”€ useSpeechRecognition.ts  # Voice input hook
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ geminiService.ts    # AI analysis & routing
â”‚   â”œâ”€â”€ liveClient.ts       # Real-time Gemini Live API
â”‚   â”œâ”€â”€ speechService.ts    # Text-to-speech output
â”‚   â””â”€â”€ audioUtils.ts       # Audio processing utilities
â”œâ”€â”€ types.ts                # TypeScript definitions
â””â”€â”€ vite.config.ts          # Build configuration
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Google Gemini** for powering the AI vision and language capabilities
- **Google AI Studio** for the development environment
- All contributors and testers who helped improve accessibility

---

<div align="center">

**Made with â¤ï¸ for accessibility**

*Empowering independence for the visually impaired*

[View in AI Studio](https://ai.studio/apps/drive/1_XfGi2NxDB6oOnBmmaHuCudS4AH5PMQB) â€¢ [Report Bug](https://github.com/vanductan-NLT/blind-eye/issues) â€¢ [Request Feature](https://github.com/vanductan-NLT/blind-eye/issues)

</div>
